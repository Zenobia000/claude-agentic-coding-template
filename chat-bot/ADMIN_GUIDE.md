# ç®¡ç†å“¡æŒ‡å—

## ğŸ“‹ ç›®éŒ„

1. [ç’°å¢ƒé…ç½®](#ç’°å¢ƒé…ç½®)
2. [æ¨¡å‹ç®¡ç†](#æ¨¡å‹ç®¡ç†)
3. [æœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰](#æœ¬åœ°æ¨¡å‹ollama)
4. [çŸ¥è­˜åº«ç®¡ç†](#çŸ¥è­˜åº«ç®¡ç†)
5. [æ¶æ§‹èªªæ˜](#æ¶æ§‹èªªæ˜)
6. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
7. [æ•ˆèƒ½å„ªåŒ–](#æ•ˆèƒ½å„ªåŒ–)

---

## ç’°å¢ƒé…ç½®

### API Keys è¨­ç½®

åœ¨**å°ˆæ¡ˆæ ¹ç›®éŒ„**å‰µå»º `.env` æ–‡ä»¶ï¼š

```bash
# OpenAIï¼ˆå¿…é ˆï¼‰
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxx

# Anthropicï¼ˆå¯é¸ï¼‰
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx

# Googleï¼ˆå¯é¸ï¼‰
GOOGLE_API_KEY=xxxxxxxxxxxxxxxxxxxxx
```

### æœå‹™å•Ÿå‹•

```bash
cd 05-project-development

# å•Ÿå‹•æ‰€æœ‰æœå‹™
docker compose up -d --build

# æŸ¥çœ‹æ—¥èªŒ
docker compose logs -f backend

# é‡å•Ÿç‰¹å®šæœå‹™
docker compose restart backend

# åœæ­¢æ‰€æœ‰æœå‹™
docker compose down
```

### é–‹ç™¼æ¨¡å¼

Backend å·²å•Ÿç”¨è‡ªå‹•é‡è¼‰ï¼š

```dockerfile
# backend/Dockerfile
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

**ä¿®æ”¹ç¨‹å¼ç¢¼å¾Œè‡ªå‹•ç”Ÿæ•ˆï¼Œç„¡éœ€é‡å•Ÿï¼**

---

## æ¨¡å‹ç®¡ç†

### æ¨¡å‹é…ç½®æ–‡ä»¶

æ‰€æœ‰æ¨¡å‹åœ¨ `backend/models_config.json` ä¸­é›†ä¸­ç®¡ç†ï¼š

```json
{
  "æä¾›å•†åç¨±": {
    "æ¨¡å‹é¡åˆ¥": [
      {
        "id": "æ¨¡å‹ID",
        "label": "é¡¯ç¤ºæ¨™ç±¤",
        "tags": ["æ¨™ç±¤1", "æ¨™ç±¤2"]
      }
    ]
  }
}
```

### æ¨¡å‹é¡åˆ¥

| é¡åˆ¥ | èªªæ˜ | ç”Ÿæˆ RAG | é¡¯ç¤ºçµ¦ä½¿ç”¨è€… |
|------|------|---------|------------|
| `chat_multimodal` | å°è©±æ¨¡å‹ | âœ… | âœ… |
| `reasoning` | æ¨ç†æ¨¡å‹ | âœ… | âœ… |
| `embedding` | åµŒå…¥æ¨¡å‹ | âŒ | âŒ å…§éƒ¨ä½¿ç”¨ |
| `audio_realtime` | éŸ³è¨Šæ¨¡å‹ | âŒ | âŒ æš«ä¸é–‹æ”¾ |

### æ·»åŠ æ–°æ¨¡å‹

**æ­¥é©Ÿ 1ï¼šç·¨è¼¯é…ç½®**

```bash
nano backend/models_config.json
```

æ·»åŠ æ¨¡å‹ï¼š

```json
{
  "openai": {
    "chat_multimodal": [
      {
        "id": "gpt-5-turbo",           // æ–°æ¨¡å‹
        "label": "openai_gpt_5_turbo",
        "tags": ["chat", "next_gen"]
      }
    ]
  }
}
```

**æ­¥é©Ÿ 2ï¼šé‡å•Ÿæœå‹™**

```bash
docker compose restart backend
```

**å°±é€™æ¨£ï¼** ç³»çµ±æœƒè‡ªå‹•ï¼š
- âœ… è¼‰å…¥ `gpt-5-turbo`
- âœ… ç”Ÿæˆ `gpt-5-turbo-rag`
- âœ… åœ¨ UI ä¸­é¡¯ç¤º

### æ·»åŠ æ–°æä¾›å•†

**ç¤ºä¾‹ï¼šæ·»åŠ  Cohere**

**1. æ›´æ–° models_config.json**

```json
{
  "cohere": {
    "chat_multimodal": [
      {
        "id": "command-r-plus",
        "label": "cohere_command_r_plus",
        "tags": ["chat", "multilingual"]
      }
    ]
  }
}
```

**2. æ·»åŠ  API Key**

```bash
# .env
COHERE_API_KEY=xxxxxxxxxxxxxxxxxxxxx
```

**3. æ›´æ–° config.py**

```python
class Settings(BaseSettings):
    COHERE_API_KEY: str = os.getenv("COHERE_API_KEY", "")
```

**4. æ›´æ–° model_manager.py**

```python
elif provider == "cohere":
    from langchain_cohere import ChatCohere
    return ChatCohere(
        model=base_model_id,
        temperature=temperature,
        cohere_api_key=self.settings.COHERE_API_KEY
    )
```

**5. æ›´æ–° requirements.txt**

```
langchain-cohere==x.x.x
```

**6. é‡æ–°æ§‹å»º**

```bash
docker compose up -d --build backend
```

### æŸ¥çœ‹å¯ç”¨æ¨¡å‹

```bash
curl http://localhost:8000/v1/models | python3 -m json.tool
```

---

## æœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰

### æœå‹™ç‹€æ…‹æª¢æŸ¥

```bash
# æª¢æŸ¥ Ollama æœå‹™
curl http://localhost:11434/api/tags

# æŸ¥çœ‹å·²ä¸‹è¼‰çš„æ¨¡å‹
docker exec 05-project-development-ollama-1 ollama list
```

### å‘½ä»¤åˆ—ç®¡ç†

```bash
# ä¸‹è¼‰æ¨¡å‹
docker exec 05-project-development-ollama-1 ollama pull llama3.2:3b

# åˆªé™¤æ¨¡å‹
docker exec 05-project-development-ollama-1 ollama rm llama3.2:3b

# æŸ¥çœ‹ç£ç¢Ÿä½¿ç”¨
du -sh ./ollama_data
```

### GPU é…ç½®

**æª¢æŸ¥ GPU ä½¿ç”¨ï¼š**

```bash
nvidia-smi
# é‹è¡Œæ¨¡å‹æ™‚æ‡‰è©²çœ‹åˆ° ollama é€²ç¨‹
```

**å¦‚æœæ²’æœ‰ GPUï¼ˆä½¿ç”¨ CPUï¼‰ï¼š**

ç·¨è¼¯ `docker-compose.yml`ï¼š

```yaml
ollama:
  image: ollama/ollama:latest
  ports:
    - "11434:11434"
  volumes:
    - ./ollama_data:/root/.ollama
  # è¨»é‡‹æ‰ deploy éƒ¨åˆ†
  # deploy:
  #   resources:
  #     reservations:
  #       devices:
  #         - driver: nvidia
  #           count: all
  #           capabilities: [gpu]
```

### æ¨è–¦é è£æ¨¡å‹

```bash
# å¿«é€Ÿæ¨¡å‹ï¼ˆæ¨è–¦æ–°æ‰‹ï¼‰
docker exec 05-project-development-ollama-1 ollama pull llama3.2:3b

# ä¸­æ–‡æ¨¡å‹
docker exec 05-project-development-ollama-1 ollama pull qwen2.5:7b

# ç¨‹å¼ç¢¼æ¨¡å‹
docker exec 05-project-development-ollama-1 ollama pull codellama:7b
```

---

## çŸ¥è­˜åº«ç®¡ç†

### é›™ RAG æ¶æ§‹

æœ¬ç³»çµ±æœ‰**å…©å¥— RAG**ï¼š

```
1. Open WebUI Knowledge (ChromaDB)
   â”œâ”€ å„²å­˜ï¼š./open-webui/vector_db/
   â”œâ”€ ç”¨é€”ï¼šä½¿ç”¨è€…è‡ªä¸»ä¸Šå‚³çš„æ–‡æª”
   â””â”€ ä½¿ç”¨ï¼šåœ¨å°è©±ä¸­ç”¨ # å¼•ç”¨

2. Backend RAG (Qdrant)
   â”œâ”€ å„²å­˜ï¼š./qdrant_storage/
   â”œâ”€ ç”¨é€”ï¼šé å…ˆç´¢å¼•çš„å°ˆæ¥­æ–‡æª”
   â””â”€ ä½¿ç”¨ï¼šé¸æ“‡å¸¶ -rag å¾Œç¶´çš„æ¨¡å‹
```

### è·è²¬åŠƒåˆ†

| å ´æ™¯ | ä½¿ç”¨æ–¹å¼ | è³‡æ–™ä½ç½® |
|------|---------|---------|
| ä½¿ç”¨è€…è‡¨æ™‚ä¸Šå‚³ PDF | Knowledge åŠŸèƒ½ | ChromaDB |
| ä¼æ¥­è«–æ–‡åº« | -rag æ¨¡å‹ | Qdrant |
| æœƒè­°æ–‡æª”åˆ†æ | Knowledge åŠŸèƒ½ | ChromaDB |
| API æœå‹™ | -rag æ¨¡å‹ | Qdrant |

### ç›£æ§å„²å­˜ä½¿ç”¨

```bash
# ChromaDB ä½¿ç”¨
du -sh ./open-webui/vector_db/

# Qdrant ä½¿ç”¨
du -sh ./qdrant_storage/

# ç¸½è¨ˆ
du -sh ./open-webui/ ./qdrant_storage/
```

### æŸ¥çœ‹çŸ¥è­˜åº«

**ChromaDBï¼ˆOpen WebUIï¼‰ï¼š**

```bash
sqlite3 ./open-webui/webui.db "SELECT name, description FROM knowledge;"
```

**Qdrantï¼ˆBackendï¼‰ï¼š**

è¨ªå•ï¼š`http://localhost:6333/dashboard`

### å‚™ä»½çŸ¥è­˜åº«

```bash
# å‚™ä»½ Open WebUI è³‡æ–™
tar -czf openwebui-backup-$(date +%Y%m%d).tar.gz ./open-webui/

# å‚™ä»½ Qdrant è³‡æ–™
tar -czf qdrant-backup-$(date +%Y%m%d).tar.gz ./qdrant_storage/

# å‚™ä»½æ‰€æœ‰è³‡æ–™
tar -czf full-backup-$(date +%Y%m%d).tar.gz ./open-webui/ ./qdrant_storage/ ./ollama_data/
```

### æ¸…ç†è³‡æ–™

```bash
# æ¸…ç† Open WebUI è³‡æ–™ï¼ˆKnowledge + èŠå¤©è¨˜éŒ„ï¼‰
rm -rf ./open-webui/

# æ¸…ç† Qdrant è³‡æ–™
rm -rf ./qdrant_storage/

# æ¸…ç† Ollama æ¨¡å‹
rm -rf ./ollama_data/

# é‡æ–°å•Ÿå‹•
docker compose up -d
```

---

## æ¶æ§‹èªªæ˜

### æœå‹™æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä½¿ç”¨è€…ç€è¦½å™¨â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Open WebUI  â”‚â”€â”€â”€â”€â†’â”‚  Backend    â”‚
â”‚  (å‰ç«¯)     â”‚     â”‚  (RAG API)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChromaDB   â”‚     â”‚   Qdrant    â”‚
â”‚ (è‡¨æ™‚æ–‡æª”)  â”‚     â”‚ (å°ˆæ¥­çŸ¥è­˜åº«) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Ollama    â”‚
        â”‚ (æœ¬åœ°æ¨¡å‹)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç«¯å£æ˜ å°„

| æœå‹™ | ç«¯å£ | ç”¨é€” |
|------|------|------|
| Open WebUI | 8081 | å‰ç«¯ç•Œé¢ |
| Backend | 8000 | RAG API |
| Qdrant | 6333 | å‘é‡è³‡æ–™åº« |
| Ollama | 11434 | æœ¬åœ°æ¨¡å‹æœå‹™ |

### è³‡æ–™æµå‘

**ç´” LLM å°è©±ï¼š**
```
ä½¿ç”¨è€… â†’ Open WebUI â†’ Backend â†’ LLM API â†’ è¿”å›
```

**RAG æ¨¡å¼ï¼ˆ-ragï¼‰ï¼š**
```
ä½¿ç”¨è€… â†’ Open WebUI â†’ Backend â†’ Qdrant æª¢ç´¢ â†’ LLM API â†’ è¿”å›
```

**Knowledge åŠŸèƒ½ï¼š**
```
ä½¿ç”¨è€… â†’ Open WebUI â†’ ChromaDB æª¢ç´¢ â†’ LLM API â†’ è¿”å›
```

---

## æ•…éšœæ’é™¤

### å•é¡Œ 1ï¼šæ¨¡å‹ä¸é¡¯ç¤º

**æª¢æŸ¥æ¸…å–®ï¼š**

```bash
# 1. API Key æ˜¯å¦è¨­ç½®ï¼Ÿ
cat /path/to/project/.env | grep API_KEY

# 2. Backend æ˜¯å¦å•Ÿå‹•ï¼Ÿ
docker compose ps backend

# 3. æŸ¥çœ‹éŒ¯èª¤æ—¥èªŒ
docker compose logs backend | grep -i error

# 4. é©—è­‰ API
curl http://localhost:8000/v1/models
```

### å•é¡Œ 2ï¼šRAG ä¸å·¥ä½œ

**æª¢æŸ¥ï¼š**

```bash
# 1. å¥åº·æª¢æŸ¥
curl http://localhost:8000/health

# 2. Qdrant æ˜¯å¦é‹è¡Œï¼Ÿ
curl http://localhost:6333/

# 3. Collection æ˜¯å¦å­˜åœ¨ï¼Ÿ
curl http://localhost:6333/collections

# 4. æŸ¥çœ‹ RAG æ—¥èªŒ
docker compose logs backend | grep RAG
```

### å•é¡Œ 3ï¼šOllama ä¸‹è¼‰å¤±æ•—

**è§£æ±ºæ–¹æ¡ˆï¼š**

```bash
# 1. æª¢æŸ¥ç¶²è·¯
ping ollama.com

# 2. æŸ¥çœ‹ Ollama æ—¥èªŒ
docker compose logs ollama

# 3. æ‰‹å‹•ä¸‹è¼‰
docker exec -it 05-project-development-ollama-1 sh
ollama pull llama3.2:3b

# 4. æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h
```

### å•é¡Œ 4ï¼šè¨˜æ†¶é«”ä¸è¶³

**å„ªåŒ–æ–¹æ¡ˆï¼š**

```bash
# 1. åœæ­¢ä¸éœ€è¦çš„æœå‹™
docker compose stop ollama  # å¦‚æœä¸ç”¨æœ¬åœ°æ¨¡å‹

# 2. é™åˆ¶å®¹å™¨è¨˜æ†¶é«”
# docker-compose.yml
services:
  backend:
    deploy:
      resources:
        limits:
          memory: 2G

# 3. ä½¿ç”¨å°æ¨¡å‹
# é¸æ“‡ mini/haiku ç‰ˆæœ¬
```

### æŸ¥çœ‹æ—¥èªŒ

```bash
# æ‰€æœ‰æœå‹™
docker compose logs -f

# ç‰¹å®šæœå‹™
docker compose logs -f backend
docker compose logs -f open-webui
docker compose logs -f qdrant
docker compose logs -f ollama

# æœ€è¿‘ 100 è¡Œ
docker compose logs --tail=100 backend

# æœå°‹éŒ¯èª¤
docker compose logs backend | grep -i error
```

---

## æ•ˆèƒ½å„ªåŒ–

### æ¨¡å‹é¸æ“‡å„ªåŒ–

**æˆæœ¬å„ªåŒ–ï¼š**

```json
{
  "tags": ["cheap", "fast"]  // æ¨™è¨˜ä¾¿å®œçš„æ¨¡å‹
}
```

æ¨è–¦ä¾¿å®œæ¨¡å‹ï¼š
- `gpt-4o-mini`
- `claude-haiku-4-5`
- `gemini-2.5-flash`

**æ•ˆèƒ½å„ªåŒ–ï¼š**

ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ¸›è¼• API è² æ“”ï¼š

```
80% æµé‡ â†’ Ollamaï¼ˆå…è²»ï¼‰
20% æµé‡ â†’ API æ¨¡å‹ï¼ˆé«˜å“è³ªï¼‰
```

### å‘é‡è³‡æ–™åº«å„ªåŒ–

**Qdrant é…ç½®ï¼š**

```yaml
# docker-compose.yml
qdrant:
  environment:
    - QDRANT__SERVICE__GRPC_PORT=6334  # å•Ÿç”¨ gRPCï¼ˆæ›´å¿«ï¼‰
```

**ç´¢å¼•å„ªåŒ–ï¼š**

```python
# å»ºç«‹ç´¢å¼•æ™‚ä½¿ç”¨æ‰¹æ¬¡æ“ä½œ
qdrant_client.upsert(
    collection_name="docs",
    points=points,  # æ‰¹æ¬¡æ’å…¥è€Œä¸æ˜¯é€å€‹æ’å…¥
    wait=False      # éåŒæ­¥å¯«å…¥
)
```

### è³‡æºç›£æ§

```bash
# æŸ¥çœ‹å®¹å™¨è³‡æºä½¿ç”¨
docker stats

# æŸ¥çœ‹ç£ç¢Ÿä½¿ç”¨
df -h
du -sh ./open-webui/ ./qdrant_storage/ ./ollama_data/

# æŸ¥çœ‹è¨˜æ†¶é«”ä½¿ç”¨
free -h
```

---

## ç”Ÿç”¢éƒ¨ç½²å»ºè­°

### å®‰å…¨é…ç½®

1. **ä½¿ç”¨ Secrets ç®¡ç† API Keys**

```yaml
# docker-compose.prod.yml
services:
  backend:
    secrets:
      - openai_api_key
secrets:
  openai_api_key:
    file: ./secrets/openai_api_key.txt
```

2. **å•Ÿç”¨ HTTPS**

```yaml
# ä½¿ç”¨ Nginx åå‘ä»£ç†
nginx:
  image: nginx:latest
  volumes:
    - ./nginx.conf:/etc/nginx/nginx.conf
    - ./ssl:/etc/nginx/ssl
  ports:
    - "443:443"
```

3. **è¨ªå•æ§åˆ¶**

```python
# main.py
from fastapi.security import HTTPBearer

security = HTTPBearer()

@app.post("/v1/chat/completions")
async def chat(credentials: HTTPAuthorizationCredentials = Security(security)):
    # é©—è­‰ token
    ...
```

### é«˜å¯ç”¨é…ç½®

**å¤šå¯¦ä¾‹ Backendï¼š**

```yaml
backend:
  deploy:
    replicas: 3  # é‹è¡Œ 3 å€‹å¯¦ä¾‹
```

**å¤–éƒ¨ Qdrantï¼š**

```yaml
# ä½¿ç”¨ Qdrant Cloud æˆ–ç¨ç«‹é›†ç¾¤
backend:
  environment:
    - QDRANT_URL=https://qdrant-cluster.example.com
```

### ç›£æ§èˆ‡æ—¥èªŒ

```bash
# ä½¿ç”¨ Prometheus + Grafana
# æˆ–
# ä½¿ç”¨ ELK Stackï¼ˆElasticsearch + Logstash + Kibanaï¼‰
```

---

## é·ç§»èˆ‡å‡ç´š

### çµ±ä¸€å‘é‡åº«é·ç§»

**å¦‚æœæ±ºå®šçµ±ä¸€ä½¿ç”¨ Qdrantï¼š**

```yaml
# docker-compose.yml
open-webui:
  environment:
    - VECTOR_DB=qdrant
    - QDRANT_URI=http://qdrant:6333
```

**è³‡æ–™é·ç§»è…³æœ¬ï¼š**

```python
# migrate_chromadb_to_qdrant.py
import chromadb
from qdrant_client import QdrantClient

# 1. é€£æ¥ ChromaDB
chroma_client = chromadb.PersistentClient(path="./open-webui/vector_db")

# 2. é€£æ¥ Qdrant
qdrant_client = QdrantClient(url="http://localhost:6333")

# 3. é·ç§»è³‡æ–™
for collection in chroma_client.list_collections():
    # è®€å– ChromaDB
    # å¯«å…¥ Qdrant
    ...
```

### ç‰ˆæœ¬å‡ç´š

```bash
# å‚™ä»½è³‡æ–™
./backup.sh

# æ‹‰å–æœ€æ–°é¡åƒ
docker compose pull

# é‡æ–°æ§‹å»º
docker compose up -d --build

# é©—è­‰
curl http://localhost:8000/health
```

---

## ç¶­è­·æ¸…å–®

### æ¯æ—¥

- [ ] æª¢æŸ¥æœå‹™ç‹€æ…‹ï¼š`docker compose ps`
- [ ] æŸ¥çœ‹éŒ¯èª¤æ—¥èªŒï¼š`docker compose logs backend | grep ERROR`

### æ¯é€±

- [ ] å‚™ä»½è³‡æ–™ï¼š`./backup.sh`
- [ ] æª¢æŸ¥ç£ç¢Ÿç©ºé–“ï¼š`df -h`
- [ ] æ¸…ç†èˆŠæ—¥èªŒï¼š`docker system prune`

### æ¯æœˆ

- [ ] æ›´æ–°é¡åƒï¼š`docker compose pull && docker compose up -d`
- [ ] å¯©æŸ¥ API ä½¿ç”¨æˆæœ¬
- [ ] å„ªåŒ–æ¨¡å‹é…ç½®

### æ¯å­£åº¦

- [ ] è©•ä¼°é›™å‘é‡åº«ä½¿ç”¨æƒ…æ³
- [ ] è€ƒæ…®æ˜¯å¦é·ç§»åˆ°çµ±ä¸€ Qdrant
- [ ] æ•ˆèƒ½æ¸¬è©¦èˆ‡å„ªåŒ–

---

## å¿«é€Ÿå‘½ä»¤åƒè€ƒ

```bash
# å•Ÿå‹•
docker compose up -d --build

# åœæ­¢
docker compose down

# é‡å•Ÿ
docker compose restart

# æŸ¥çœ‹æ—¥èªŒ
docker compose logs -f backend

# é€²å…¥å®¹å™¨
docker compose exec backend sh

# å‚™ä»½è³‡æ–™
tar -czf backup.tar.gz ./open-webui/ ./qdrant_storage/

# æ¸…ç†è³‡æ–™
rm -rf ./open-webui/ ./qdrant_storage/ ./ollama_data/

# é©—è­‰å¥åº·
curl http://localhost:8000/health
curl http://localhost:8000/v1/models
```

---

**éœ€è¦ä½¿ç”¨è€…ä½¿ç”¨æŒ‡å—ï¼Ÿ** æŸ¥çœ‹ [USER_GUIDE.md](USER_GUIDE.md)

**å°ˆæ¡ˆæ¦‚è¿°ï¼Ÿ** æŸ¥çœ‹ [README.md](README.md)

